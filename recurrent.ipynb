{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=None, test_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words are typically represented by tokens in a numeric dictionary where each word corresponds to an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 27595, 28842, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "87\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "803\n"
     ]
    }
   ],
   "source": [
    "print(word_index['computer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "decoded_news = ' '.join([reverse_word_index.get(i - 3, '') for i in x_train[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              mcgrath rentcorp said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
     ]
    }
   ],
   "source": [
    "print(decoded_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Embedding](https://www.tensorflow.org/images/audio-image-text.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embedding\n",
    "\n",
    "Words live in a discrete space that is sparse and orthogonal, which severely suffers from the curse of dimensionality. Word embedding is basically a mapping from this challenging space to a lower dimensional vector space that is more dense and correlated. \n",
    "\n",
    "https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Recurrent](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent neural networks\n",
    "\n",
    "Recurrent neural networks allow for language patterns beyond keywords as entire sentences can be entered as input sequences. Recurrent neural networks can handle input sequences of varying lengths and share parameters in time.\n",
    "\n",
    "http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "\n",
    "\n",
    "https://www.coursera.org/lecture/nlp-sequence-models/backpropagation-through-time-bc7ED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "('x_train shape:', (8982, 100))\n",
      "('x_test shape:', (2246, 100))\n"
     ]
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=100)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=100)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert class vector to binary class matrix (for use with categorical_crossentropy)\n",
      "('y_train shape:', (8982, 46))\n",
      "('y_test shape:', (2246, 46))\n"
     ]
    }
   ],
   "source": [
    "print('Convert class vector to binary class matrix '\n",
    "      '(for use with categorical_crossentropy)')\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(30980, 20))\n",
    "model.add(LSTM(20, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 20)          619600    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 46)                966       \n",
      "=================================================================\n",
      "Total params: 623,846\n",
      "Trainable params: 623,846\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/15\n",
      "8982/8982 [==============================] - 37s 4ms/step - loss: 2.6426 - acc: 0.3244 - val_loss: 2.4174 - val_acc: 0.3620\n",
      "Epoch 2/15\n",
      "8982/8982 [==============================] - 35s 4ms/step - loss: 2.3603 - acc: 0.3712 - val_loss: 2.1401 - val_acc: 0.4724\n",
      "Epoch 3/15\n",
      "8982/8982 [==============================] - 34s 4ms/step - loss: 2.0013 - acc: 0.4841 - val_loss: 1.8407 - val_acc: 0.5071\n",
      "Epoch 4/15\n",
      "8982/8982 [==============================] - 35s 4ms/step - loss: 1.7718 - acc: 0.5295 - val_loss: 1.7512 - val_acc: 0.5485\n",
      "Epoch 5/15\n",
      "8982/8982 [==============================] - 36s 4ms/step - loss: 1.6472 - acc: 0.5635 - val_loss: 1.7033 - val_acc: 0.5663\n",
      "Epoch 6/15\n",
      "8982/8982 [==============================] - 35s 4ms/step - loss: 1.5508 - acc: 0.5915 - val_loss: 1.6725 - val_acc: 0.5739\n",
      "Epoch 7/15\n",
      "8982/8982 [==============================] - 34s 4ms/step - loss: 1.4480 - acc: 0.6145 - val_loss: 1.6524 - val_acc: 0.5877\n",
      "Epoch 8/15\n",
      "8982/8982 [==============================] - 36s 4ms/step - loss: 1.3792 - acc: 0.6339 - val_loss: 1.6433 - val_acc: 0.5944\n",
      "Epoch 9/15\n",
      "8982/8982 [==============================] - 36s 4ms/step - loss: 1.3045 - acc: 0.6549 - val_loss: 1.6436 - val_acc: 0.5935\n",
      "Epoch 10/15\n",
      "8982/8982 [==============================] - 37s 4ms/step - loss: 1.2387 - acc: 0.6713 - val_loss: 1.6620 - val_acc: 0.5957\n",
      "Epoch 11/15\n",
      "8982/8982 [==============================] - 37s 4ms/step - loss: 1.1822 - acc: 0.6853 - val_loss: 1.6673 - val_acc: 0.6095\n",
      "Epoch 12/15\n",
      "8982/8982 [==============================] - 40s 4ms/step - loss: 1.1227 - acc: 0.7060 - val_loss: 1.6587 - val_acc: 0.6215\n",
      "Epoch 13/15\n",
      "8982/8982 [==============================] - 38s 4ms/step - loss: 1.0699 - acc: 0.7247 - val_loss: 1.6759 - val_acc: 0.6198\n",
      "Epoch 14/15\n",
      "8982/8982 [==============================] - 38s 4ms/step - loss: 1.0143 - acc: 0.7408 - val_loss: 1.6904 - val_acc: 0.6282\n",
      "Epoch 15/15\n",
      "8982/8982 [==============================] - 37s 4ms/step - loss: 0.9601 - acc: 0.7568 - val_loss: 1.6906 - val_acc: 0.6322\n",
      "2246/2246 [==============================] - 1s 549us/step\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=15,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further readings\n",
    "\n",
    "https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks\n",
    "\n",
    "https://bair.berkeley.edu/blog/2018/08/06/recurrent/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
